{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primera Limpieza y Filtrado del Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraccion del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerias usadas en el script\n",
    "import pandas as pd\n",
    "from fractions import Fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraccion de datos (es necesario descomprimir los zips en /Dataset Comprimido o reemplazar la ubicacion en read_csv)\n",
    "tables = [\"common_player_info\", \"draft_combine_stats\", \"draft_history\", \"game_info\", \"game\", \"inactive_players\",\n",
    "          \"line_score\", \"other_stats\", \"play_by_play\", \"player\", \"team_details\", \"team\"]\n",
    "\n",
    "# Cargar cada archivo CSV en un DataFrame con el nombre del elemento en `tables`\n",
    "for table_name in tables:\n",
    "    globals()[table_name] = pd.read_csv(f\"csv/{table_name}.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtro de datos por fecha y por jugadores drafteados y consecuentes filtros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombrar columnas para evitar ambiguedades y para igualar nombres de columnas que tienen los mismos atributos\n",
    "rename_columns = {\n",
    "    'common_player_info': {\n",
    "        'person_id': 'player_id',\n",
    "        'display_first_last': 'player_name',\n",
    "        'draft_round': 'round_pick',\n",
    "        'draft_year': 'draft_season'\n",
    "        \n",
    "    },\n",
    "    'draft_history': {\n",
    "        'person_id': 'player_id',\n",
    "        'round_number': 'draft_number',\n",
    "        'season': 'draft_season'\n",
    "    },\n",
    "    'draft_combine_stats': {\n",
    "        'height_w_shoes': 'height',\n",
    "        'height_wo_shoes': 'height_w_shoes',\n",
    "        'season': 'draft_season'\n",
    "        \n",
    "    },\n",
    "    'team': {\n",
    "        'id': 'team_id',\n",
    "        'full_name': 'team_name'\n",
    "    },\n",
    "    'player': {\n",
    "        'id': 'player_id',\n",
    "        'full_name': 'player_name'\n",
    "    },\n",
    "    'inactive_players': {\n",
    "        'jersey_num': 'jersey'\n",
    "    },\n",
    "    'line_score': {\n",
    "        'game_date_est': 'game_date'\n",
    "    },\n",
    "    'team_details': {\n",
    "        'abbreviation': 'team_abbreviation',\n",
    "        'nickname': 'team_nickname',\n",
    "        'city': 'team_city',\n",
    "        'yearfounded': 'year_founded'\n",
    "\n",
    "    },\n",
    "    'team': {\n",
    "        'abbreviation': 'team_abbreviation',\n",
    "        'nickname': 'team_nickname',\n",
    "        'city': 'team_city',\n",
    "        'state': 'team_state'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Aplicar renombramiento en cada dataframe\n",
    "for df_name, renames in rename_columns.items():\n",
    "    globals()[df_name].rename(columns=renames, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar columnas para tratarlas durante el script\n",
    "columnas_string = ['player_id', 'player_name', 'school', 'country', 'last_affiliation', 'jersey', 'position', \n",
    "'team_id', 'team_name', 'team_abbreviation', 'team_code', 'team_city', 'playercode',\n",
    "'position', 'draft_type', 'organization', 'organization_type', 'game_id', 'team_id_home',\n",
    "'team_abbreviation_home', 'team_name_home', 'matchup_home', 'team_id_away',\n",
    "'team_abbreviation_away', 'team_name_away', 'matchup_away', 'season_type', 'team_city_name_home',\n",
    "'team_nickname_home', 'team_city_name_away', 'team_nickname_away', 'league_id', 'eventnum',\n",
    "'eventmsgtype', 'eventmsgactiontype', 'homedescription', 'visitordescription', 'score',\n",
    "'person1type', 'player1_id', 'player1_name', 'player1_team_id', 'player1_team_city', \n",
    "'player1_team_nickname', 'player1_team_abbreviation', 'player2_id', 'player2_name',\n",
    "'player2_team_id', 'player2_team_city', 'player2_team_nickname', 'player2_team_abbreviation',\n",
    "'player3_id', 'player3_name', 'player3_team_id', 'player3_team_city', 'player3_team_nickname',\n",
    "'player3_team_abbreviation', 'owner', 'generalmanager', 'headcoach', 'dleagueaffiliation', 'team_state',\n",
    "'season_exp', 'from_year', 'to_year', 'draft_year', 'round_pick', 'draft_number', 'season',\n",
    "'overall_pick', 'season_id', 'arena', 'year_founded', 'draft_season']\n",
    "columnas_bool = ['rosterstatus', 'games_played_current_season_flag', 'dleague_flag', 'nba_flag',\n",
    "'games_played_flag', 'greatest_75_flag', 'player_profile_flag', 'wl_home', 'video_available_home',\n",
    "'wl_away', 'video_available_away', 'video_available_flag', 'is_active']\n",
    "columnas_date = ['birthdate', 'game_date']\n",
    "columnas_timestring = ['game_time', 'wctimestring', 'pctimestring']\n",
    "columnas_pulgadas = ['height', 'height_wo_shoes', 'height_w_shoes', 'wingspan', 'standing_reach', 'hand_length',\n",
    "'hand_width', 'standing_vertical_leap', 'max_vertical_leap']\n",
    "columnas_libras = ['weight']\n",
    "columnas_float3 = ['body_fat_pct', 'fg_pct_home', 'fg3_pct_home', 'ft_pct_home', 'fg_pct_away', 'fg3_pct_away', 'ft_pct_away']\n",
    "columnas_tiempo = ['lane_agility_time', 'modified_lane_agility_time', 'three_quarter_sprint']\n",
    "columnas_int = ['bench_press', 'attendance', 'fgm_home',\n",
    "'fga_home', 'fg3m_home', 'fg3a_home', 'ftm_home', 'fta_home', 'oreb_home', 'dreb_home',\n",
    "'reb_home', 'ast_home', 'stl_home', 'blk_home', 'tov_home', 'pts_home', 'plus_minus_home',\n",
    "'fgm_away', 'fga_away', 'fg3m_away', 'fg3a_away', 'ftm_away', 'fta_away', 'oreb_away',\n",
    "'dreb_away', 'reb_away', 'ast_away', 'stl_away', 'blk_away', 'tov_away', 'pf_away', 'pts_away',\n",
    "'plus_minus_away', 'game_sequence', 'pts_qtr1_home', 'pts_qtr2_home', 'pts_qtr3_home',\n",
    "'pts_qtr4_home', 'pts_ot1_home', 'pts_ot2_home', 'pts_ot3_home', 'pts_ot4_home', 'pts_ot5_home',\n",
    "'pts_ot6_home', 'pts_ot7_home', 'pts_ot8_home', 'pts_ot9_home', 'pts_ot10_home', 'pts_home',\n",
    "'pts_qtr1_away', 'pts_qtr2_away', 'pts_qtr3_away', 'pts_qtr4_away', 'pts_ot1_away',\n",
    "'pts_ot2_away', 'pts_ot3_away', 'pts_ot4_away', 'pts_ot5_away', 'pts_ot6_away', 'pts_ot7_away',\n",
    "'pts_ot8_away', 'pts_ot9_away', 'pts_ot10_away', 'pts_away', 'pts_paint_home', 'pts_2nd_chance_home',\n",
    "'pts_fb_home', 'largest_lead_home', 'lead_changes', 'times_tied', 'team_turnovers_home',\n",
    "'total_turnovers_home', 'team_rebounds_home', 'pts_off_to_home', 'pts_paint_away',\n",
    "'pts_2nd_chance_away', 'pts_fb_away', 'largest_lead_away', 'team_turnovers_away',\n",
    "'total_turnovers_away', 'team_rebounds_away', 'pts_off_to_away', 'period', 'scoremargin', 'arenacapacity']\n",
    "columnas_fracciones = ['spot_fifteen_corner_left', 'spot_fifteen_break_left', 'spot_fifteen_top_key',\n",
    "'spot_fifteen_break_right', 'spot_fifteen_corner_right', 'spot_college_corner_left',\n",
    "'spot_college_break_left', 'spot_college_top_key', 'spot_college_break_right',\n",
    "'spot_college_corner_right', 'spot_nba_corner_left', 'spot_nba_break_left',\n",
    "'spot_nba_top_key', 'spot_nba_break_right', 'spot_nba_corner_right',\n",
    "'off_drib_fifteen_break_left', 'off_drib_fifteen_top_key', 'off_drib_fifteen_break_right',\n",
    "'off_drib_college_break_left', 'off_drib_college_top_key', 'off_drib_college_break_right',\n",
    "'on_move_fifteen', 'on_move_college']\n",
    "columnas_ratios = ['team_wins_losses_home', 'team_wins_losses_away']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar por año\n",
    "for table_name in tables:\n",
    "    if 'game_date' in globals()[table_name].columns:\n",
    "        globals()[table_name]['game_date'] = pd.to_datetime(globals()[table_name]['game_date'])\n",
    "        globals()[table_name] = globals()[table_name][globals()[table_name]['game_date'].dt.year > 1999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar draft_combine_stats para obtener solo los registros que tengan informacion acerca de las pruebas de tiro en alguna de las ligas\n",
    "# crear una máscara para obtener los registros con al menos 5 valores no nulos en 'columnas_fracciones' (evaluaciones de tiros al aro)\n",
    "mask = draft_combine_stats[columnas_fracciones].notna().sum(axis=1) >= 5\n",
    "\n",
    "# Aplicar la mascara para filtrar afuera del df los registros que no cumplen la condicion\n",
    "draft_combine_stats = draft_combine_stats[mask].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar los datos del resto de los df por los df ya filtrados\n",
    "# Crear listas con los ID's unicos de los df filtrados para filtrar con esos ID's el resto de los df\n",
    "unique_game_ids = game['game_id'].unique().tolist()\n",
    "unique_player_ids = draft_combine_stats['player_id'].unique().tolist()\n",
    "\n",
    "\n",
    "# Loop through each DataFrame name in the tables list, filtering based on game_id if the column exists\n",
    "for table_name in tables:\n",
    "    df = globals()[table_name]\n",
    "    if 'player_id' in df.columns:\n",
    "        globals()[table_name] = df[df['player_id'].isin(unique_player_ids)]\n",
    "\n",
    "for table_name in tables:\n",
    "    df = globals()[table_name]\n",
    "    if 'game_id' in df.columns:\n",
    "        globals()[table_name] = df[df['game_id'].isin(unique_game_ids)]\n",
    "\n",
    "\n",
    "# Filtrar play_by_play\n",
    "play_by_play = play_by_play[\n",
    "    play_by_play['player1_id'].isin(unique_player_ids) |\n",
    "    play_by_play['player2_id'].isin(unique_player_ids) |\n",
    "    play_by_play['player3_id'].isin(unique_player_ids)\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1: Obtener valores únicos de player1_id, player2_id y player3_id\n",
    "unique_players = pd.concat([\n",
    "    play_by_play['player1_id'],\n",
    "    play_by_play['player2_id'],\n",
    "    play_by_play['player3_id']\n",
    "]).dropna().unique()\n",
    "\n",
    "# Convertir a un conjunto para eficiencia en la búsqueda\n",
    "unique_players_set = set(unique_players)\n",
    "\n",
    "# Paso 2: Filtrar cada DataFrame en tables para que solo contenga registros con player_id en unique_players_set\n",
    "filtered_tables = []\n",
    "for df in tables:\n",
    "    if 'player_id' in globals()[df].columns:\n",
    "        # Filtrar el DataFrame con base en unique_players_set\n",
    "        globals()[f'f_{df}'] = globals()[df][globals()[df]['player_id'].isin(unique_players_set)]\n",
    "        filtered_tables.append(f'f_{df}')\n",
    "    else:\n",
    "        # Mantener el DataFrame sin cambios si no tiene 'player_id'\n",
    "        filtered_tables.append(f'f_{df}')\n",
    "\n",
    "# Ahora filtered_tables contiene los DataFrames con registros filtrados o sin cambios según corresponda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asegurar la integridad de los datos en su contenido y formato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegúrate de que 'player_id' en ambos DataFrames esté en el mismo formato, por ejemplo, tipo int\n",
    "common_player_info['player_id'] = common_player_info['player_id'].astype(int)\n",
    "draft_combine_stats['player_id'] = draft_combine_stats['player_id'].astype(int)\n",
    "\n",
    "# Realizar el merge entre common_player_info y draft_combine_stats basado en player_id\n",
    "merged_df = common_player_info.merge(\n",
    "    draft_combine_stats[['player_id', 'height_1']],\n",
    "    on='player_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Reemplazar directamente los valores de 'height' con 'height_wo_shoes'\n",
    "merged_df['height'] = merged_df['height_1']\n",
    "\n",
    "# Eliminar la columna 'height_wo_shoes' ya que solo se usaba para llenar valores en 'height'\n",
    "merged_df = merged_df.drop(columns=['height_1'])\n",
    "\n",
    "# Actualizar common_player_info con los registros actualizados\n",
    "common_player_info = merged_df\n",
    "\n",
    "# Mostrar el DataFrame actualizado\n",
    "print(common_player_info)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar Columnas que no se vayan a usar\n",
    "# Diccionario con los nombres de columnas que se vayan a eliminar como listas que contienen en sus valores los df donde\n",
    "# estan presentes\n",
    "columns_to_drop = {\n",
    "    'first_name': ['common_player_info', 'draft_combine_stats', 'inactive_players', 'player'],\n",
    "    'last_name': ['common_player_info', 'draft_combine_stats', 'inactive_players', 'player'],\n",
    "    'display_fi_last': ['common_player_info'],\n",
    "    'display_last_comma_first': ['common_player_info'],\n",
    "    'player_slug': ['common_player_info'],\n",
    "    'facebook': ['team_details'],\n",
    "    'instagram': ['team_details'],\n",
    "    'twitter': ['team_details'],\n",
    "    'neutraldescription': ['play_by_play'],\n",
    "    'height_w_shoes_ft_in': ['draft_combine_stats'],\n",
    "    'height_wo_shoes_ft_in': ['draft_combine_stats'],\n",
    "    'wingspan_ft_in': ['draft_combine_stats'],\n",
    "    'standing_reach_ft_in': ['draft_combine_stats']\n",
    "}\n",
    "\n",
    "# Iterar cada columna y su dataframe correspondiente\n",
    "for column, dfs in columns_to_drop.items():\n",
    "    for df_name in dfs:\n",
    "        df = globals()[df_name]  # Accede al df por su nombre\n",
    "        if column in df.columns:  # Verifica si la columna existe\n",
    "            df.drop(columns=[column], inplace=True)  # Dropear la columna\n",
    "            print(f\"Column '{column}' removed from {df_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar columnas de fracciones a su formato correcto\n",
    "dataframes = [draft_combine_stats]  # los dataframes donde hay fracciones que necesitan reformateo\n",
    "\n",
    "# Definir la funcion de conversion\n",
    "def to_fraction(value):\n",
    "    if isinstance(value, str) and '-' in value:\n",
    "        parts = value.split('-')\n",
    "        if len(parts) == 2 and parts[0].isdigit() and parts[1].isdigit():\n",
    "            x, y = parts\n",
    "            return Fraction(int(x), int(y))     # Devuelve valor en formato fraccion\n",
    "        return value                            # Devuelve el valor original si no se encuentra en formato x - y\n",
    "\n",
    "\n",
    "# Applicar la transformacion a cada columna dentro de 'columnas_fracciones'\n",
    "for df in dataframes:\n",
    "    for col in columnas_fracciones:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].apply(to_fraction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rellenar valores nulos en game (wl_home, ft_pct_home, wl_away, ft_pct_away)\n",
    "# Aquí definimos la lógica para rellenar wl_home y wl_away\n",
    "def set_wl(row):\n",
    "    if row['pts_home'] > row['pts_away']:\n",
    "        return pd.Series(['W', 'L'])  # wl_home, wl_away\n",
    "    else:\n",
    "        return pd.Series(['L', 'W'])  # wl_home, wl_away\n",
    "\n",
    "# Aplicamos la función y rellenamos las columnas correspondientes\n",
    "game[['wl_home', 'wl_away']] = game.apply(set_wl, axis=1)\n",
    "\n",
    "\n",
    "def calculate_pct(row):\n",
    "    row['fg_pct_home'] = row['fgm_home'] / row['fga_home'] if row['fga_home'] != 0 else 0\n",
    "    row['fg_pct_away'] = row['fgm_away'] / row['fga_away'] if row['fga_away'] != 0 else 0\n",
    "    row['fg3_pct_home'] = row['fg3m_home'] / row['fg3a_home'] if row['fg3a_home'] != 0 else 0\n",
    "    row['fg3_pct_away'] = row['fg3m_away'] / row['fg3a_away'] if row['fg3a_away'] != 0 else 0\n",
    "    row['ft_pct_home'] = row['ftm_home'] / row['fta_home'] if row['fta_home'] != 0 else 0\n",
    "    row['ft_pct_away'] = row['ftm_away'] / row['fta_away'] if row['fta_away'] != 0 else 0\n",
    "    return row\n",
    "\n",
    "# Aplicamos la función a cada fila\n",
    "game = game.apply(calculate_pct, axis=1)\n",
    "\n",
    "# Verificamos el resultado\n",
    "game.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_player_info = common_player_info.drop_duplicates(subset=['player_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtén las columnas que están en draft_combine_stats y common_player_info\n",
    "columns_to_exclude = set(draft_combine_stats.columns).union(set(common_player_info.columns))\n",
    "\n",
    "# Selecciona solo las columnas de draft_history que no están en columns_to_exclude\n",
    "columns_to_merge = [col for col in draft_history.columns if col not in columns_to_exclude]\n",
    "\n",
    "# Realiza el merge con las columnas filtradas\n",
    "draft_history_stats = draft_combine_stats.merge(\n",
    "    draft_history[['player_id'] + columns_to_merge],\n",
    "    on='player_id',\n",
    "    how='left'  # Unión izquierda para incluir todos los registros de draft_combine_stats\n",
    ")\n",
    "\n",
    "# Muestra el resultado\n",
    "print(draft_history_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecciona solo las columnas de draft_history que no están en columns_to_exclude\n",
    "columns_to_merge = [col for col in player.columns if col not in common_player_info.columns]\n",
    "# Realiza un merge de common_player_info y player en player_info basado en player_id\n",
    "player_info = common_player_info.merge(\n",
    "    player[['player_id'] + columns_to_merge],\n",
    "    on='player_id',\n",
    "    how='inner'  # Este tipo de join solo incluirá los player_id que están en ambos DataFrames\n",
    ")\n",
    "\n",
    "# Encuentra las columnas comunes entre ambos DataFrames, excluyendo 'player_id' y 'player_name'\n",
    "columns_to_drop = player_info.columns.intersection(draft_history_stats.columns).difference(['player_id', 'player_name'])\n",
    "\n",
    "# Elimina las columnas de player_info que están en draft_history_stats, excepto 'player_id' y 'player_name'\n",
    "player_info = player_info.drop(columns=columns_to_drop)\n",
    "\n",
    "# Muestra el resultado\n",
    "print(player_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecciona solo las columnas de draft_history que no están en columns_to_exclude\n",
    "columns_to_merge = [col for col in game_info.columns if col not in game.columns]\n",
    "# Realiza un merge de common_player_info y player en player_info basado en player_id\n",
    "game_data = game.merge(\n",
    "    game_info[['game_id'] + columns_to_merge],\n",
    "    on='game_id',\n",
    "    how='left' \n",
    ")\n",
    "\n",
    "columns_to_merge = [col for col in line_score.columns if col not in game_data.columns]\n",
    "# Realiza un merge de common_player_info y player en player_info basado en player_id\n",
    "game_data = game_data.merge(\n",
    "    line_score[['game_id'] + columns_to_merge],\n",
    "    on='game_id',\n",
    "    how='left' \n",
    ")\n",
    "\n",
    "columns_to_merge = [col for col in other_stats.columns if col not in game_data.columns]\n",
    "# Realiza un merge de common_player_info y player en player_info basado en player_id\n",
    "game_data = game_data.merge(\n",
    "    other_stats[['game_id'] + columns_to_merge],\n",
    "    on='game_id',\n",
    "    how='left' \n",
    ")\n",
    "\n",
    "# Muestra el resultado\n",
    "print(game_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecciona solo las columnas de draft_history que no están en columns_to_exclude\n",
    "columns_to_merge = [col for col in team_details.columns if col not in team.columns]\n",
    "# Realiza un merge de common_player_info y player en player_info basado en player_id\n",
    "team_info = team.merge(\n",
    "    team_details[['team_id'] + columns_to_merge],\n",
    "    on='team_id',\n",
    "    how='left' \n",
    ")\n",
    "\n",
    "print(team_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Realizamos un merge de 'play_by_play' con 'draft_history' usando 'player3_id' y 'player_id'\n",
    "merged_df = play_by_play.merge(\n",
    "    draft_history_stats[['player_id', 'player_name']],\n",
    "    how='left',\n",
    "    left_on='player1_id',\n",
    "    right_on='player_id'\n",
    ")\n",
    "\n",
    "# Rellenamos los valores nulos de las columnas de 'play_by_play' con los valores correspondientes de 'draft_history'\n",
    "merged_df['player1_name'] = merged_df['player1_name'].combine_first(merged_df['player_name'])\n",
    "\n",
    "merged_df = merged_df[play_by_play.columns]\n",
    "\n",
    "# Realizamos un merge de 'play_by_play' con 'draft_history' usando 'player3_id' y 'player_id'\n",
    "merged_df = merged_df.merge(\n",
    "    draft_history_stats[['player_id', 'player_name']],\n",
    "    how='left',\n",
    "    left_on='player2_id',\n",
    "    right_on='player_id'\n",
    ")\n",
    "\n",
    "# Rellenamos los valores nulos de las columnas de 'play_by_play' con los valores correspondientes de 'draft_history'\n",
    "merged_df['player2_name'] = merged_df['player2_name'].combine_first(merged_df['player_name'])\n",
    "\n",
    "merged_df = merged_df[play_by_play.columns]\n",
    "\n",
    "\n",
    "# Realizamos un merge de 'play_by_play' con 'draft_history' usando 'player3_id' y 'player_id'\n",
    "merged_df = play_by_play.merge(\n",
    "    draft_history_stats[['player_id', 'player_name']],\n",
    "    how='left',\n",
    "    left_on='player3_id',\n",
    "    right_on='player_id'\n",
    ")\n",
    "\n",
    "# Rellenamos los valores nulos de las columnas de 'play_by_play' con los valores correspondientes de 'draft_history'\n",
    "merged_df['player3_name'] = merged_df['player3_name'].combine_first(merged_df['player_name'])\n",
    "\n",
    "# Eliminamos las columnas adicionales para regresar al formato original\n",
    "play_by_play = merged_df[play_by_play.columns]\n",
    "\n",
    "\n",
    "\n",
    "# Realizamos un merge de 'play_by_play' con 'draft_history' usando 'player2_id' y 'player_id'\n",
    "merged_df = play_by_play.merge(\n",
    "    common_player_info[['player_id', 'player_name', 'team_code', 'team_id', 'team_city', 'team_abbreviation']],\n",
    "    how='left',\n",
    "    left_on='player2_id',\n",
    "    right_on='player_id'\n",
    ")\n",
    "\n",
    "# Rellenamos los valores nulos de las columnas de 'play_by_play' con los valores correspondientes de 'draft_history'\n",
    "merged_df['player2_name'] = merged_df['player2_name'].combine_first(merged_df['player_name'])\n",
    "merged_df['player2_team_nickname'] = merged_df['player2_team_nickname'].combine_first(merged_df['team_code'])\n",
    "merged_df['player2_team_id'] = merged_df['player2_team_id'].combine_first(merged_df['team_id'])\n",
    "merged_df['player2_team_city'] = merged_df['player2_team_city'].combine_first(merged_df['team_city'])\n",
    "merged_df['player2_team_abbreviation'] = merged_df['player2_team_abbreviation'].combine_first(merged_df['team_abbreviation'])\n",
    "\n",
    "# Eliminamos las columnas adicionales para regresar al formato original\n",
    "play_by_play = merged_df[play_by_play.columns]\n",
    "\n",
    "# Realizamos un merge de 'play_by_play' con 'draft_history' usando 'player3_id' y 'player_id'\n",
    "merged_df = play_by_play.merge(\n",
    "    common_player_info[['player_id', 'player_name', 'team_code', 'team_id', 'team_city', 'team_abbreviation']],\n",
    "    how='left',\n",
    "    left_on='player3_id',\n",
    "    right_on='player_id'\n",
    ")\n",
    "\n",
    "# Rellenamos los valores nulos de las columnas de 'play_by_play' con los valores correspondientes de 'draft_history'\n",
    "merged_df['player3_name'] = merged_df['player3_name'].combine_first(merged_df['player_name'])\n",
    "merged_df['player3_team_nickname'] = merged_df['player3_team_nickname'].combine_first(merged_df['team_code'])\n",
    "merged_df['player3_team_id'] = merged_df['player3_team_id'].combine_first(merged_df['team_id'])\n",
    "merged_df['player3_team_city'] = merged_df['player3_team_city'].combine_first(merged_df['team_city'])\n",
    "merged_df['player3_team_abbreviation'] = merged_df['player3_team_abbreviation'].combine_first(merged_df['team_abbreviation'])\n",
    "\n",
    "# Eliminamos las columnas adicionales para regresar al formato original\n",
    "play_by_play = merged_df[play_by_play.columns]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea un DataFrame con los registros únicos de 'player_id' y 'player_name'\n",
    "players= draft_history_stats[['player_id', 'player_name']].drop_duplicates()\n",
    "print(players.shape)\n",
    "print(draft_history_stats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Itera sobre las columnas del DataFrame\n",
    "for col in draft_history_stats.columns:\n",
    "    if col in columnas_fracciones:\n",
    "        # Aplica una transformación a la columna para convertir fracciones en decimales\n",
    "        draft_history_stats[col] = draft_history_stats[col].apply(\n",
    "            lambda x: float(x.split('/')[0]) / float(x.split('/')[1]) if isinstance(x, str) and '/' in x else x\n",
    "        )\n",
    "\n",
    "        # Formatea la columna a float con 2 decimales\n",
    "        draft_history_stats[col] = draft_history_stats[col].astype(float).round(3)\n",
    "\n",
    "# Imprime el DataFrame para verificar los cambios\n",
    "print(draft_history_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manejo de valores nulos restantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = ['game_data','play_by_play','inactive_players','player_info','draft_history_stats','players','team_info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rellenar valores nulos de common_player_info, draft_combine_stats, game_info, inactive_players, line_score, other_stats\n",
    "player_info.fillna(0, inplace=True)\n",
    "draft_history_stats.fillna(0, inplace=True)\n",
    "game_data.fillna(0, inplace=True)\n",
    "inactive_players.fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rellenar resto de valores nulos con N/A ya que son strings entonces permiten ser rellenados de esa forma\n",
    "for table_name in tables:\n",
    "    globals()[table_name].fillna('N/A', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recorremos cada DataFrame en la lista 'tables'\n",
    "for df in tables:\n",
    "    # Reemplazamos 'N/A' por 0 en las columnas que están en 'columnas_int'\n",
    "    for column in columnas_int:\n",
    "        if column in globals()[df].columns:\n",
    "            globals()[df][column] = globals()[df][column].replace('N/A', 0)\n",
    "            globals()[df][column] = globals()[df][column].replace('TIE', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicacion de formatos correspondientes\n",
    "# Recorrer cada DataFrame en la lista tables\n",
    "for df in tables:\n",
    "    \n",
    "    # Convertir columnas a string\n",
    "    for col in globals()[df].columns.intersection(columnas_string + columnas_bool + columnas_timestring):\n",
    "        globals()[df][col] = globals()[df][col].astype(str)\n",
    "    \n",
    "    # Convertir columnas a datetime\n",
    "    for col in globals()[df].columns.intersection(columnas_date):\n",
    "        globals()[df][col] = pd.to_datetime(globals()[df][col])  # 'coerce' convierte valores inválidos a NaT\n",
    "    \n",
    "    '''# Aplicar formato para columnas en pulgadas\n",
    "    for col in globals()[df].columns.intersection(columnas_pulgadas):\n",
    "        globals()[df][col] = globals()[df][col].astype(float).map(lambda x: f\"{x:.2f} in\")\n",
    "    \n",
    "    # Aplicar formato para columnas en libras\n",
    "    for col in globals()[df].columns.intersection(columnas_libras):\n",
    "        globals()[df][col] = globals()[df][col].astype(float).map(lambda x: f\"{x:.2f} lbs\")'''\n",
    "    \n",
    "    # Aplicar formato para columnas float con 3 decimales\n",
    "    for col in globals()[df].columns.intersection(columnas_float3):\n",
    "        globals()[df][col] = globals()[df][col].astype(float).round(3)\n",
    "    \n",
    "    '''# Aplicar formato para columnas de tiempo en segundos\n",
    "    for col in globals()[df].columns.intersection(columnas_tiempo):\n",
    "        globals()[df][col] = globals()[df][col].astype(float).map(lambda x: f\"{x:.3f} segs\")'''\n",
    "    \n",
    "    # Convertir columnas a enteros\n",
    "    for col in globals()[df].columns.intersection(columnas_int):\n",
    "        globals()[df][col] = globals()[df][col].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escritura de los dataframes filtrados en archivos .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for table_name in tables:\n",
    "    globals()[table_name].to_csv(f'C:/Users/1sant/OneDrive/Escritorio/Backup/Curso Data Analytics/Proyecto Final/Dataset/Filtrados/csv/f_{table_name}.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
